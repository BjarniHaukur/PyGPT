{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 3.31M\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0364,  0.9826,  0.2212,  ...,  0.3989,  0.3396,  0.6336],\n",
       "          [-0.4094,  0.5396,  0.7782,  ...,  0.2645, -0.0385,  0.7553],\n",
       "          [-0.0253,  0.6822,  0.0424,  ...,  0.2293,  0.4163, -0.0330],\n",
       "          ...,\n",
       "          [-0.2189,  0.5299,  0.2904,  ..., -0.1705,  0.1550,  0.0511],\n",
       "          [-0.4040,  0.5109, -0.0689,  ..., -0.1278,  0.4097, -0.0200],\n",
       "          [-0.3201,  0.6264, -0.0254,  ..., -0.0381,  0.1772, -0.1399]]],\n",
       "        grad_fn=<UnsafeViewBackward0>),\n",
       " tensor(5.6912, grad_fn=<NllLossBackward0>))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from models import load_config, model_from_config\n",
    "\n",
    "config = load_config(\"transformer_small\")\n",
    "model = model_from_config(config)\n",
    "\n",
    "x = torch.ones(1, 512).long()\n",
    "model(x, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,  ..., 169, 391, 175],\n",
       "        [  0,   0,   0,  ..., 515,  95, 259],\n",
       "        [  0,   0,   0,  ...,  81,  20, 515],\n",
       "        ...,\n",
       "        [  0,   0,   0,  ..., 337, 379, 300],\n",
       "        [  0,   0,   0,  ..., 188,  58, 515],\n",
       "        [  0,   0,   0,  ..., 426,  19, 406]], device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(torch.zeros(32,8).long().cuda(), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 512]), torch.Size([32, 128]), torch.Size([32, 128]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = torch.randint(0, 570, (32, 512)).cuda()\n",
    "B, L = batch.shape\n",
    "context = int(0.25 * L)\n",
    "pred_length = 2 * context\n",
    "x = batch[:, :context]\n",
    "y = batch[:, context:pred_length]\n",
    "\n",
    "y_hat = model.generate(x, L)[:, context:pred_length]\n",
    "\n",
    "batch.shape, x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.metrics import bleu_score, syntax_error_score\n",
    "bleu_score(y.tolist(), y_hat.tolist(), n_gram=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.tokenizer import BOS_ID, BPETokenizer\n",
    "\n",
    "tokenizer = BPETokenizer.load(\"py150k_large\")\n",
    "y_hat = model.generate(torch.tensor([[BOS_ID]*B]).long().cuda(), L)\n",
    "\n",
    "programs = [tokenizer.detokenize(gen_seq) for gen_seq in y_hat.tolist()]\n",
    "syntax_error_score(programs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import model_from_checkpoint\n",
    "from utils.tokenizer import BPETokenizer, BOS_ID, EOS_ID, PAD_ID\n",
    "\n",
    "model = model_from_checkpoint(\"medium-lstm-run/epoch_8.pt\", device=\"cpu\")\n",
    "tokenizer = BPETokenizer.load(\"py150k_large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset import MemmapDataset\n",
    "\n",
    "ds = MemmapDataset(\"train\", \"py150k_large\")\n",
    "ds.tokenizer.detokenize(ds[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = model.generate(4, 100, nucleus_threshold=0.5)\n",
    "programs = [tokenizer.detokenize(tokens) for tokens in samples]\n",
    "\n",
    "for program in programs[:10]:\n",
    "    print(tokenizer.color_text_ansi(program))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.search import beam_search\n",
    "\n",
    "code = \"\"\"class ListV\"\"\"\n",
    "\n",
    "tokens = beam_search(model, max_length=100, starting_tokens=tokenizer.tokenize(code))\n",
    "print(tokenizer.detokenize(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in samples:\n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "code = \"\"\"class \"\"\"\n",
    "\n",
    "tokens = torch.tensor(tokenizer.tokenize(code)).unsqueeze(0)\n",
    "\n",
    "pred = model.generate(1, max_len=100, starting_tokens=tokens, nucleus_threshold=0.5)\n",
    "\n",
    "print(tokenizer.color_text_ansi(tokenizer.detokenize(pred[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tokenizer.detokenize(pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset, DataLoader, random_split\n",
    "\n",
    "def collate_fn(batch:list[torch.Tensor], max_len:int=2048):\n",
    "    batch = [x[:max_len] for x in batch]\n",
    "    batch = [\n",
    "        torch.cat([torch.tensor([BOS_ID]), x, torch.tensor([EOS_ID])])\n",
    "        for x in batch\n",
    "    ]\n",
    "    return torch.nn.utils.rnn.pad_sequence(batch, batch_first=True, padding_value=PAD_ID)\n",
    "\n",
    "\n",
    "train_ds = MemmapDataset(\"train\", \"py150k_large\")\n",
    "val_ds = MemmapDataset(\"eval\", \"py150k_large\")\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=32, collate_fn=collate_fn)\n",
    "val_dl = DataLoader(val_ds, batch_size=32, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import bleu_score, syntax_error_score\n",
    "\n",
    "batch = next(iter(val_dl))\n",
    "B, L = batch.shape\n",
    "# avoid going to the end of the batch (may be padded)\n",
    "context = int(0.25 * L)\n",
    "pred_length = 2 * context\n",
    "x = batch[:, :context]\n",
    "y = batch[:, context:pred_length]\n",
    "y_hat = model.generate(B, max_len=L, starting_tokens=x, nucleus_threshold=0.5)\n",
    "y_hat = [seq[context:pred_length] for seq in y_hat]\n",
    "avg_bleu_score = bleu_score(y.tolist(), y_hat, n_gram=4)\n",
    "            \n",
    "gen = model.generate(B, max_len=200, nucleus_threshold=0.5)\n",
    "programs = [tokenizer.detokenize(gen_seq) for gen_seq in gen]\n",
    "avg_syntax_error_score = syntax_error_score(programs)\n",
    "\n",
    "avg_bleu_score, avg_syntax_error_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.detokenize(y[-2].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.detokenize(y_hat[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
