model_type: PyTransformer
wandb_project: PyGPT
wandb_group: Transformers
tokenizer_name: py150k_large
block_size: 512
vocab_size: 2176
n_layer: 16
n_head: 16
n_embd: 1024
dropout: 0.1
bias: False 